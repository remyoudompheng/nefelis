"""
Sieve for the GF(p²) discrete logarithm

Currently only degree 2 polynomials are implemented using the
conjugate method.

The method is as follows:
* select gj(x) = g1(x) + sqrt(D) g2(x) with small Q[sqrt(D)] coefficients
* consider f = |gj| = g1^2 - D g2^2 with small integer coefficients
* consider g = u g1 + v g2 where (v/u)^2=D modulo p

In general, the group of combined symmetries of quadratics (g1,g2)
is generated by 2 linear reflections.

Since these reflections will usually swap roots of g modulo l,
we only sieve half of special-q to avoid duplicates caused by this
extra symmetry.
"""

from typing import Iterator

import argparse
import concurrent.futures
from concurrent.futures import ProcessPoolExecutor
import json
import logging
import math
from multiprocessing import current_process
import os
import pathlib
import time

import flint

from nefelis import cadocompat
from nefelis import integers
from nefelis.sieve import Siever, eta as sieve_eta, gen_specialq
from nefelis.fp2 import polyselect

logger = logging.getLogger("sieve")

# If True, assume that the linear algebra step
# will consider all ideals without the conjugacy relation.
DEBUG_IGNORE_CONJUGATES = False


class Factorer:
    def __init__(self, f, g, gj, B2f, B2g):
        self.f = f
        self.g = g
        self.gj = gj
        self.B2f = B2f
        self.B2g = B2g

    def ideal_proj(self, x, y, facf):
        (cx, cy), (bx, by), (ax, ay) = self.gj
        xx, xy, yy = x * x, x * y, y * y
        num = ax * xx + bx * xy + cx * yy
        den = ay * xx + by * xy + cy * yy
        # assert num**2 - D * den**2 == 0 mod l
        return [num * pow(den, -1, l) % l if den % l else l for l in facf]

    def factor_fg(self, q, chunk):
        res = []
        f = self.f
        C, B, A = self.g
        for x, y in chunk:
            x, y = int(x), int(y)
            if math.gcd(x, y) != 1:
                continue
            # value = u * x + v * y
            # print(f"{x}+{y}i", flint.fmpz(value).factor())
            # Output in Cado format
            # x,y:(factors of g(x) in hex):(factors of f(x) in hex)
            vf = abs(
                x * x * (f[4] * x * x + f[3] * x * y + f[2] * y * y)
                + y * y * y * (f[1] * x + f[0] * y)
            )
            vg = abs(A * x * x + B * x * y + C * y * y) // q

            facf = []
            for _l, _e in integers.factor_smooth(vf, self.B2f):
                facf += _e * [int(_l)]
            if any(_f.bit_length() > self.B2f for _f in facf):
                continue

            facg = [q]
            for _l, _e in integers.factor_smooth(vg, self.B2g):
                facg += _e * [int(_l)]

            if any(_l.bit_length() > self.B2g for _l in facg):
                continue

            facf.sort()
            facg.sort()
            # Since we are interested in ideals of f up to conjugacy,
            # we only need to determine the corresponding ideal of Q(sqrt(D))
            # which is determined by f1(x,y)/f2(x,y) which is a square root of D.
            if DEBUG_IGNORE_CONJUGATES:
                idealf = [x * pow(y, -1, _l) % _l if y % _l else _l for _l in facf]
                idealg = [x * pow(y, -1, _l) % _l if y % _l else _l for _l in facg]
            else:
                idealf = self.ideal_proj(x, y, facf)
                idealg = [0 for _ in facg]
                # print([i*i % l for i, l in zip(idealf, facf)])
            res.append((x, y, facf, facg, idealf, idealg))

        return res


FACTORER = None


def factorer_init(f, g, gj, B2f, B2g):
    global FACTORER
    FACTORER = Factorer(f, g, gj, B2f, B2g)


def factorer_task(args):
    q, chunk = args
    return FACTORER.factor_fg(q, chunk)


SIEVER = None


def worker_init(gpu_ids: list[int] | None, *args):
    global SIEVER
    if gpu_ids is None:
        gpu_idx = 0
    else:
        proc = current_process()
        gpu_idx = gpu_ids[proc._identity[-1] % len(gpu_ids)]
    SIEVER = Siever(*args, gpu_idx=gpu_idx)


def worker_task(args):
    q, qr = args
    t = time.monotonic()
    reports = SIEVER.sieve(q, qr)
    return q, qr, time.monotonic() - t, reports


# The parameters are similar to deg3 for 2x larger N
PARAMS = [
    # bitsize, B1g, B2g, B2f, cofactor bits, I=logwidth, qmin
    (40, 8_000, 15, 14, 5, 13, 200),
    (50, 9_000, 16, 15, 5, 13, 500),
    (60, 10_000, 17, 16, 5, 13, 1_000),
    (70, 20_000, 18, 16, 5, 13, 1_000),
    (80, 25_000, 18, 17, 5, 13, 1_000),
    (90, 30_000, 18, 18, 5, 13, 2_000),
    # 1 large prime
    (100, 40_000, 19, 18, 20, 13, 3_000),
    (110, 50_000, 19, 19, 21, 13, 5_000),
    (120, 80_000, 19, 19, 21, 14, 2_000),
    (130, 150_000, 20, 19, 22, 14, 3_000),
    (140, 300_000, 21, 19, 22, 14, 4_000),
    (150, 500_000, 21, 20, 23, 14, 5_000),
    (160, 1000_000, 22, 20, 24, 14, 8_000),
    (170, 1500_000, 22, 21, 24, 14, 10_000),
    (180, 2500_000, 23, 21, 24, 14, 20_000),
    (190, 3000_000, 23, 22, 25, 14, 40_000),
    (200, 5000_000, 24, 22, 26, 14, 50_000),
    (210, 7000_000, 24, 23, 27, 14, 100_000),
    (220, 10_000_000, 25, 23, 27, 14, 200_000),
    (230, 15_000_000, 25, 24, 28, 14, 300_000),
    (240, 20_000_000, 26, 24, 28, 14, 500_000),
    # 2 large primes
    # (240, 10_000_000, 26, 25, 48, 14, 200_000),
]

# Parameters for GPU factor
PARAMS2 = [
    # bitsize, B1f, thrF
    (40, 5_000, 30),
    (60, 30_000, 30),
    (80, 40_000, 30),
    (90, 50_000, 35),
    (100, 60_000, 35),
    (120, 80_000, 32),
    (140, 90_000, 27),
    (150, 100_000, 28),
    (160, 150_000, 28),
    (170, 300_000, 27),
    (180, 350_000, 27),
    (190, 350_000, 28),
    (200, 400_000, 28),
    (220, 500_000, 26),
    (240, 500_000, 25),
    # (240, 800_000, 28),
]


def get_params(N):
    return min(PARAMS, key=lambda p: abs(p[0] - N.bit_length()))[1:]


def get_params2(N):
    return min(PARAMS2, key=lambda p: abs(p[0] - N.bit_length()))[1:]


def conway_poly(p):
    """
    Compute a Conway polynomial for field GF(p^2)

    >>> conway_poly(2)
    [1, -1, 1]
    >>> conway_poly(63361)
    [37, -17, 1]
    >>> conway_poly(65537)
    [3, -1, 1]
    >>> conway_poly(94009)
    [13, -13, 1]
    """
    # The root of the Conway polynomial must map to the root of the
    # Conway polynomial of degree 1 under the norm map.
    l0 = integers.factor(p - 1)
    for c in range(1, p):
        if any(pow(c, (p - 1) // l, p) == 1 for l, _ in l0):
            continue
        logging.debug(f"Conway: {c} is primitive modulo p")
        break
    # The leading coefficient is always 1
    l1 = integers.factor(p + 1)
    Fp2 = flint.fq_default_ctx(p, 2)
    Fp2X = flint.fq_default_poly_ctx(Fp2)
    for b in range(p):
        r = Fp2X([c, -b, 1]).roots()[0][0]
        if r ** (p - 1) == 1:
            continue
        if any(r ** ((p * p - 1) // l) == 1 for l, _ in l1):
            continue
        logging.debug(f"Conway: x²-{b}*x+{c} is the Conway polynomial")
        break

    return [c, -b, 1]


def main():
    argp = argparse.ArgumentParser()
    argp.add_argument(
        "--nogpufactor", action="store_true", help="Don't perform trial division on GPU"
    )

    def gpu_id(s: str) -> list[int]:
        return [int(x) for x in s.split(",")]

    argp.add_argument("--gpu", type=gpu_id, help="List of GPU devices to be used")
    argp.add_argument("--ncpu", type=int, help="CPU threads for factoring")
    argp.add_argument("N", type=int)
    argp.add_argument("WORKDIR")
    args = argp.parse_args()

    logging.getLogger().setLevel(level=logging.DEBUG)
    main_impl(args)


def main_impl(args):
    N = args.N
    datadir = pathlib.Path(args.WORKDIR)
    datadir.mkdir(exist_ok=True)

    assert flint.fmpz(N).is_prime()

    ell = integers.factor_smooth(N + 1, 16)[-1][0]

    B1g, B2g, B2f, COFACTOR_BITS, I, qmin = get_params(N)
    B1f, thr2 = 0, 0
    if not args.nogpufactor:
        B1f, thr2 = get_params2(N)
    logging.info(
        f"Sieving with B1={B1g / 1000:.0f}k,{B1f / 1000:.0f}k log(B2)={B2g},{B2f} q={qmin}.. {COFACTOR_BITS} cofactor bits"
    )

    f, g, D, gj = polyselect.polyselect(N)
    # Check roots
    ZnX = flint.fmpz_mod_poly_ctx(N)
    fn = flint.fmpz_mod_poly(f, ZnX)
    gn = flint.fmpz_mod_poly(g, ZnX)
    assert len(gn.roots()) == 0
    assert fn % gn == 0

    C, B, A = g
    assert B * B - 4 * A * C < 0

    conway = conway_poly(N)
    Fp2 = flint.fq_default_ctx(N, 2, var="i", modulus=ZnX(conway))
    Fp2X = flint.fq_default_poly_ctx(Fp2)

    logger.info(f"f = {cadocompat.poly_str(f)}")
    logger.info(f"g = {cadocompat.poly_str(g)}")
    roots_g = Fp2X(g).roots()
    z = roots_g[0][0]
    if roots_g[1][0].to_list()[1] < z.to_list()[1]:
        z = roots_g[1][0]
    logger.info(f"GF(p^2) is represented by GF(p)[x] / {flint.fmpz_poly(conway)}")
    logger.info(f"Root of f,g is z = {z}")

    ls, rs = [], []
    for _l in integers.smallprimes(B1g):
        _rs = flint.nmod_poly(g, _l).roots()
        for _r, _ in _rs:
            ls.append(_l)
            rs.append(_r)

    # NOTE: due to the symmetries of polynomials g1,g2
    # we don't sieve both ideals of K(g) above a given prime
    # (they will give "mirrored" relations).
    def specialq():
        qprev = None
        for q, r in gen_specialq(qmin, g):
            if q == qprev:
                continue
            qprev = q
            yield q, r

    LOGAREA = (10 * qmin).bit_length() + 2 * I
    # We sieve g(x) which has size log2(N)/3 + 2 log2(x) but has a known factor q
    gsize = max(_gi.bit_length() for _gi in g)
    THRESHOLD = gsize + 2 * LOGAREA // 2 - (10 * qmin).bit_length() - COFACTOR_BITS

    ls2, rs2 = None, None
    if B1f > 0:
        ls2, rs2 = [], []
        for _l in integers.smallprimes(B1f):
            _rs = flint.nmod_poly(f, _l).roots()
            for _r, _ in _rs:
                ls2.append(_l)
                rs2.append(_r)

    sievepool = ProcessPoolExecutor(
        1 if args.gpu is None else len(args.gpu),
        initializer=worker_init,
        initargs=(args.gpu, g, ls, rs, THRESHOLD, I, f, ls2, rs2, thr2),
    )
    factorpool = ProcessPoolExecutor(
        args.ncpu or os.cpu_count(),
        initializer=factorer_init,
        initargs=(f, g, gj, B2f, B2g),
    )

    with open(datadir / "args.json", "w") as w:
        json.dump(
            {
                "n": N,
                "f": f,
                "g": g,
                "D": D,
                "gj": gj,
                "ell": ell,
                "conway": conway,
                "z": [int(_zi) for _zi in z.to_list()],
            },
            w,
        )
    with open(datadir / "nefelis.poly", "w") as w:
        cadocompat.export_polys(w, N, 1.0, f, g)

    AREA = 2 ** (2 * I + 1)
    seen = set()
    relf = open(datadir / "relations.sieve", "w", buffering=1)
    total = 0
    duplicates = 0

    t0 = time.monotonic()
    last_log = 0
    total_area = 0
    total_q = 0

    # Remember seen ideals: due to the conjugacy symmetry
    # we only record 1 ideal per prime norm for g
    # we only record 1 ideal per prime norm for f
    # (actually, 1/4 of primes have 2 ideals up to conjugacy and 1/4 primes have 0)
    seenf = set()
    seeng = set()

    sieve_args: Iterator[tuple[int, int]] = specialq()
    sieve_stats: list[tuple[int, int, int]] = []
    MAX_SIEVE_QUEUE = 64
    enough_rels = False
    with sievepool, factorpool:
        sieve_jobs = []
        factor_jobs = []
        while not enough_rels:
            while len(sieve_jobs) < MAX_SIEVE_QUEUE:
                sieve_jobs.append(sievepool.submit(worker_task, next(sieve_args)))
            # Always wait for at least 1 sieve
            concurrent.futures.wait(
                sieve_jobs, return_when=concurrent.futures.FIRST_COMPLETED
            )
            sieve_pending = []
            for sfut in sieve_jobs:
                if not sfut.done():
                    sieve_pending.append(sfut)
                    continue
                q, qr, dt, reports = sfut.result()
                fut = factorpool.submit(factorer_task, (q, reports))
                factor_jobs.append((q, qr, dt, len(reports), fut))
            sieve_jobs = sieve_pending

            # Throttle if factoring is late
            factor_pending = [t[-1] for t in factor_jobs]
            if len(factor_pending) > MAX_SIEVE_QUEUE:
                _c = len(factor_pending)
                for _ in concurrent.futures.as_completed(factor_pending):
                    _c -= 1
                    if _c < MAX_SIEVE_QUEUE:
                        break
            else:
                concurrent.futures.wait(
                    factor_pending, return_when=concurrent.futures.FIRST_COMPLETED
                )

            remaining = []
            for item in factor_jobs:
                q, qr, dt, nreports, fut = item
                if not fut.done():
                    remaining.append(item)
                    continue
                nrels = 0
                reschunk = fut.result()
                print(f"# q={q} r={qr}", file=relf)

                for x, y, facf, facg, idealf, idealg in reschunk:
                    # Due to the extra symmetry, we don't use x,y to deduplicate,
                    # but the sum of 2 largest primes.
                    topf = facf[-2] + facf[-1]
                    topg = facg[-2] + facg[-1]
                    xy = topf + (topg << 32)
                    if xy in seen:
                        duplicates += 1
                        continue
                    # facg will omit q
                    str_facf = ",".join(f"{_l:x}" for _l in facf)
                    str_facg = ",".join(f"{_l:x}" for _l in facg)
                    for _l, _r in zip(facf, idealf):
                        seenf.add((_l << 32) | _r)
                    for _l, _r in zip(facg, idealg):
                        seeng.add((_l << 32) | _r)
                    seen.add(xy)
                    relf.write(f"{x},{y}:{str_facg}:{str_facf}\n")
                    nrels += 1
                if nrels:
                    seeng.add(q)
                print(f"# Found {nrels} relations for {q=} (time {dt:.3f}s)", file=relf)
                total_q += 1
                total += nrels
                total_area += AREA
                elapsed = time.monotonic() - t0
                gcount = len(seeng)
                fcount = len(seenf)
                if total_q < 10 or elapsed > last_log + 1:
                    # Don't log too often.
                    last_log = elapsed
                    logger.info(
                        f"Sieved q={q} r={qr:<8} area {total_area / 1e9:.0f}G in {dt:.3f}s (speed {total_area / elapsed / 1e9:.3f}G/s): "
                        f"{nrels}/{nreports} relations, {gcount}/{fcount} Kg/Kf primes, total {total}"
                    )

                    sieve_stats.append((total, gcount, fcount))
                    if total and len(sieve_stats) % 30 == 10:
                        boundg = max(seeng) >> 32
                        boundf = max(seenf) >> 32
                        eta = sieve_eta(boundg, boundf, total // 100, sieve_stats)
                        logger.info(
                            f"Requiring {int(eta * total)} relations ({100 / eta:.1f}% done)"
                        )

                # Correct fcount because there are 4/3 primes per norm on average
                if total > 1.01 * (fcount + gcount):
                    enough_rels = True
                    break
            factor_jobs = remaining

        logger.info("Enough relations")
        [j.cancel() for j in sieve_jobs]
        [tup[-1].cancel() for tup in factor_jobs]

    # CADO-NFS requires that the relation file ends with \n
    # Print statistics in CADO-compatible format
    # elapsed_per_q = elapsed / total_q
    rels_per_q = total / total_q
    rels_per_t = total / elapsed
    relf.write(f"# Total elapsed time {elapsed:.3f}s\n")
    relf.write(
        f"# Total {total} reports [{1 / rels_per_t:.3g}s/r, {rels_per_q:.3f}r/sq] in {elapsed:.2f} elapsed s\n"
    )
    logger.info(
        f"{total} relations {duplicates} duplicates for q={qmin}..{q} in {elapsed:.3f}s"
    )
    relf.close()


if __name__ == "__main__":
    import nefelis.logging

    nefelis.logging.setup(logging.DEBUG)
    main()
