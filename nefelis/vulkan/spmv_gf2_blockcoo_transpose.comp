// Sparse matrix-vector transposed multiplication over GF(2)
//
// This variant uses the BlockCOO format.
// The matrix is cut into stripes of BM rows.
//
// Each stripe is stored in COO format (row % BM, col) packed as 32-bit values.
// The data format is constrained by total dimension < 2^32/BM.
//
// Each workgroup processes 1 stripe (we assume that wg size is a divisor
// of BM). For a typical density of 80 and BM/wgsize=16, each invocation
// will process 1280 coefficients.
//
// Typical parameters are K=1 and BM=2048 (8kB local memory)
// with a workgroup size of 128.
//
// Output is written directly to global memory using global atomics (SLOW).
//
// The shader is only used in POLYEVAL mode:
// a matrix polynomial ak X^k is given, and the computation
// is:
//   Sum(ak * V * Mat^k)

#version 450

#define WGSIZE 128

#ifndef N
#error Matrix dimension undefined
#endif

#ifndef DENSE_N
#error Dense width undefined
#endif

#ifndef K
#error Block size undefined
#endif

#if !defined(BM)
#error Stripe size undefined
#endif

#if BM % WGSIZE
#error Stripe size not a multiple of WGSIZE
#endif

#extension GL_EXT_control_flow_attributes : require
#extension GL_EXT_shader_explicit_arithmetic_types : require

// Each thread handles a row.
layout(local_size_x = WGSIZE, local_size_y = 1, local_size_z = 1) in;

layout(binding = 0) readonly buffer Dense { uint[DENSE_N] dense[]; };
layout(binding = 1) readonly buffer Sparse { uint sparse[]; };
layout(binding = 2) readonly buffer Blocks { uint sidx[]; };
// Vector of size 2N:
// even iterations do V[N:2N] = M * V[0:N]
// odd iterations do V[0:N] = M * V[N:2N]
layout(binding = 3) buffer V { uint[K] v[]; };
// Vector of identical values (1 per workgroup) indicating iteration count
layout(binding = 4) buffer Iter { uint iter[]; };
// Polynomial sum(ak X^k)
layout(binding = 5) readonly buffer Poly { uint[M][K] ak[]; };
// Output sum(M^k V ak)
layout(binding = 6) coherent buffer Wout { uint[K] wout[]; };

#define UNROLL 16

shared uint vi[BM][K];

void main() {
  uint idx = iter[gl_WorkGroupID.x];
  const uint off0 = ((idx & 1) == 0) ? 0 : N;
  const uint off1 = ((idx & 1) == 0) ? N : 0;

  // Each workgroup must handle rows BM*wgx..BM*(wgx+1)
  const uint row0 = gl_WorkGroupID.x * BM;
  const uint tidx = gl_LocalInvocationID.x;

  // Load rows once (to local memory)
  for (uint i = 0; i < BM; i += WGSIZE) {
    const uint row = row0 + i + tidx;
    if (row >= N) {
      for (uint k = 0; k < K; k++)
        vi[i + tidx][k] = 0;
    } else {
      // Initial condition: v[off1 + *] == 0
      vi[i + tidx] = v[off0 + row];
      // Clear v0 for next iteration
      for (uint k = 0; k < K; k++)
        v[off0 + row][0] = 0;
    }
  }

  barrier();
  memoryBarrierShared();

  // Evaluate polynomial for all rows in stripe.
  for (uint i = 0; i < BM; i += WGSIZE) {
    const uint row = row0 + i + tidx;
    if (row >= N)
      break;
    // wout[row] += ak[idx] * vi
    uint[K] w = wout[row];
    const uint[K] vii = vi[i + tidx];
    for (uint b = 0; b < M; b++) {
      // bit b is the dot product ak[b] * acc
      uint wi = 0;
      for (uint k = 0; k < K; k++)
        wi ^= bitCount(ak[idx][b][k] & vii[k]) & 1;
      w[b / 32] ^= (wi << (b % 32));
    }
    wout[row] = w;
  }

  // Now accumulate out[j] += vi * mij
  // All rows will accumulate to the same locations (j < DENSE_N*32K)
  for (uint j = 0; j < DENSE_N; j++) {
    uint[32][K] outj;
    for (int jj = 0; jj < 32; jj++)
      for (uint k = 0; k < K; k++)
        outj[jj][k] = 0;
    for (uint i = 0; i < BM; i += WGSIZE) {
      const uint row = row0 + i + tidx;
      if (row >= N)
        break;
      uint dij = dense[row][j];
      const uint[K] vii = vi[i + tidx];
      for (int jj = 0; jj < 32; jj++) {
        if (bitfieldExtract(dij, jj, 1) == 1) {
          for (uint k = 0; k < K; k++) {
            outj[jj][k] ^= vii[k];
          }
        }
      }
    }
    // Fold registers and xor to global memory
    for (int jj = 0; jj < 32; jj++) {
      for (uint k = 0; k < K; k++)
        atomicXor(v[off1 + 32 * j + jj][k], outj[jj][k]);
    }
  }

  // Sparse coefficients
  const uint i0 = sidx[gl_WorkGroupID.x];
  const uint i1 = sidx[gl_WorkGroupID.x + 1];
  uint i = i0;
#ifdef UNROLL
  // Partial unroll groups of UNROLL indices.
  for (i = i0; i + WGSIZE * UNROLL < i1; i += WGSIZE * UNROLL) {
    uint c[UNROLL];
    [[unroll]]
    for (uint ii = 0; ii < UNROLL; ii++)
      c[ii] = sparse[i + ii * WGSIZE + tidx];
    [[unroll]]
    for (uint ii = 0; ii < UNROLL; ii++) {
      [[unroll]]
      for (uint k = 0; k < K; k++)
        atomicXor(v[off1 + c[ii] / BM][k], vi[c[ii] % BM][k]);
    }
  }
#endif
  for (uint ii = i + tidx; ii < i1; ii += WGSIZE) {
    const uint c = sparse[ii];
    for (uint k = 0; k < K; k++)
      atomicXor(v[off1 + c / BM][k], vi[c % BM][k]);
  }
  barrier();
  if (gl_LocalInvocationID.x == 0)
    iter[gl_WorkGroupID.x] = idx + 1;
}
